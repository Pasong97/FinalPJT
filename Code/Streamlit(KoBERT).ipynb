{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install streamlit\n","!pip install pyngrok"],"metadata":{"id":"LYxG14JPa8-B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# KoBERT를 활용한 문장감정분석 모델"],"metadata":{"id":"3HOpKzKliJ2J"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31UWCw8BgeCT","executionInfo":{"status":"ok","timestamp":1675302613651,"user_tz":-540,"elapsed":20207,"user":{"displayName":"파송","userId":"14300372304596899292"}},"outputId":"e5d78e08-1daf-438d-cb6b-e902cf477c30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["## KoBERT 깃허브에서 불러오기\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n","\n","## 필요 라이브러리 설치\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uYPV_hHybsO3","outputId":"029ad6dd-6b25-49bf-f54e-3e5beaf7b5a0","executionInfo":{"status":"ok","timestamp":1675302705326,"user_tz":-540,"elapsed":91681,"user":{"displayName":"파송","userId":"14300372304596899292"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-qtf3_z4q\n","  Running command git clone --filter=blob:none --quiet 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-qtf3_z4q\n","  Resolved https://****@github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting boto3<=1.15.18\n","  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gluonnlp<=0.10.0,>=0.6.0\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.5/344.5 KB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting mxnet<=1.7.0.post2,>=1.4.0\n","  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n","  Downloading onnxruntime-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n","  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n","  Downloading torch-1.10.1-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1102397440 bytes == 0x38026000 @  0x7f5be0c93680 0x7f5be0cb3da2 0x5f714c 0x64d800 0x527022 0x504866 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x5f5ee6 0x56bbe1 0x569d8a 0x5f60c3 0x56cc92 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.9/881.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n","  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.12)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.19.6)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.19.0,>=1.18.18\n","  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n","  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.33)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.25.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.4.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.9.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n","Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (4.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.2.0)\n","Building wheels for collected packages: kobert, gluonnlp, sacremoses\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15708 sha256=b0220b3929cf6fea8a02457993fae1c1ee5cb3d5959b31417cdad63efcb56b21\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-v7egec4a/wheels/bf/5f/74/81bf3a1332130eb6629ecf58876a8746b77021e7d7b0638e91\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp38-cp38-linux_x86_64.whl size=688978 sha256=9c2c03a0e9bd44453ea4464b714959ac1c4d6e7d041076c921ad6d6ba3bafad5\n","  Stored in directory: /root/.cache/pip/wheels/b6/93/9d/2237550c409eb3ed725d6302b7897ddd9a037b40cef66dcd9c\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=b31e77c30ed903056f96f63f9f126233f3fb321e02d2a087dc8cf3825714e194\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built kobert gluonnlp sacremoses\n","Installing collected packages: tokenizers, sentencepiece, torch, sacremoses, onnxruntime, jmespath, graphviz, mxnet, huggingface-hub, gluonnlp, botocore, transformers, s3transfer, boto3, kobert\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.1+cu116\n","    Uninstalling torch-1.13.1+cu116:\n","      Successfully uninstalled torch-1.13.1+cu116\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.10.1 which is incompatible.\n","torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.10.1 which is incompatible.\n","torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed boto3-1.15.18 botocore-1.18.18 gluonnlp-0.10.0 graphviz-0.8.4 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.53)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from huggingface-hub==0.0.12->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers) (3.0.9)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}]},{"cell_type":"code","source":["cd \"/content/drive/MyDrive/final project/code/streamlit/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8EVNEGk0Ha4","executionInfo":{"status":"ok","timestamp":1675303506217,"user_tz":-540,"elapsed":1444,"user":{"displayName":"파송","userId":"14300372304596899292"}},"outputId":"baa3808f-4493-4e3f-f84f-e4c9a72aa8ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/final project/code/streamlit\n"]}]},{"cell_type":"code","source":["%%writefile KoBERT.py\n","\n","import streamlit as st\n","\n","## KoBERT\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn\n","import torch\n","import gluonnlp as nlp\n","import numpy as np\n","\n","## GPU 설정\n","device = torch.device(\"cuda:0\")  # GPU\n","\n","class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=7,\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)\n","\n","## bertmodel의 vocabulary\n","bertmodel, vocab = get_pytorch_kobert_model()\n","\n","## 모델 불러오기\n","model = torch.load('/content/drive/MyDrive/final project/data/models/7emotions_model.pt')  # GPU 사용\n","# model = torch.load('/content/drive/MyDrive/Colab Notebooks/감정분석기/model/7emotions_model.pt', map_location=torch.device('cpu'))  # CPU 사용\n","\n","## 4. 데이터 전처리(토큰화, 정수 인코딩, 패딩)\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))\n","\n","## Setting parameters\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 5\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5\n","\n","## 8. 결과물 테스트\n","## 토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","## 감정 예측\n","def predict(predict_sentence):\n","\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    model.eval()\n"," \n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","        test_eval=[]\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","\n","            if np.argmax(logits) == 0:\n","                test_eval.append(\"공포가\")\n","            elif np.argmax(logits) == 1:\n","                test_eval.append(\"놀람이\")\n","            elif np.argmax(logits) == 2:\n","                test_eval.append(\"분노가\")\n","            elif np.argmax(logits) == 3:\n","                test_eval.append(\"슬픔이\")\n","            elif np.argmax(logits) == 4:\n","                test_eval.append(\"중립이\")\n","            elif np.argmax(logits) == 5:\n","                test_eval.append(\"행복이\")\n","            elif np.argmax(logits) == 6:\n","                test_eval.append(\"혐오가\")\n","\n","        return (test_eval[0] + \" 느껴집니다.\")\n","\n","## Text Input\n","message = st.text_area(\"감정을 기록해주세요\")\n","\n","if st.button(\"기록\", key='message'):\n","    result = message.title()\n","    st.success(result)\n","    st.text(\"기록이 완료됐습니다.\")\n","\n","    ## 문장감정분석 출력\n","    st.write(predict(result))"],"metadata":{"id":"96LatJEEiT4a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675303573140,"user_tz":-540,"elapsed":356,"user":{"displayName":"파송","userId":"14300372304596899292"}},"outputId":"71a0f805-8447-46d7-de04-892ce658c9dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing KoBERT.py\n"]}]},{"cell_type":"code","source":["## ngrok 토큰 설정\n","# !ngrok authtoken 2KqC6FInSv5YFHXU6mnORM4NadD_76hbXWt9hmxC9HjWksch\n","# from pyngrok import ngrok\n","# !streamlit run test.py&>/dev/null&\n","# publ_url = ngrok.connect(addr='8501')\n","# publ_url"],"metadata":{"id":"G53UPp-Ndxg7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675229333219,"user_tz":-540,"elapsed":15136,"user":{"displayName":"조영훈","userId":"08860332104811466825"}},"outputId":"8fe7f1dd-ca12-4c76-8b8d-37046a489403"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"]},{"output_type":"execute_result","data":{"text/plain":["<NgrokTunnel: \"http://8117-34-87-4-99.ngrok.io\" -> \"http://localhost:8501\">"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# ## streamlit 종료 후 초기화 해주기!!\n","# ngrok.kill()  # url 초기화"],"metadata":{"id":"jObgbF8SdEBD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pyngrok import ngrok\n","ngrok.set_auth_token('2KqC6FInSv5YFHXU6mnORM4NadD_76hbXWt9hmxC9HjWksch')"],"metadata":{"id":"0xStyt_5-pxO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675303640934,"user_tz":-540,"elapsed":1841,"user":{"displayName":"파송","userId":"14300372304596899292"}},"outputId":"60f7b8fa-ab48-407f-9c39-ec22cbf2d3d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[]}]},{"cell_type":"code","source":["!streamlit run KoBERT.py & npx localtunnel --port 8501"],"metadata":{"id":"Y71Taobm-pm1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675303851942,"user_tz":-540,"elapsed":199336,"user":{"displayName":"파송","userId":"14300372304596899292"}},"outputId":"5ca0a8f7-b195-4358-e044-3a953d9a87b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[..................] | fetchMetadata: sill resolveWithNewModule localtunnel@2.0\u001b[0m\u001b[K\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n","\u001b[0m\n","\u001b[K\u001b[?25hnpx: installed 22 in 5.089s\n","your url is: https://smooth-ravens-report-34-90-227-214.loca.lt\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.90.227.214:8501\u001b[0m\n","\u001b[0m\n","/content/drive/MyDrive/final project/code/streamlit/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n","/content/drive/MyDrive/final project/code/streamlit/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_v1.zip\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_v1.zip\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_v1.zip\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_v1.zip\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n","using cached model. /content/drive/MyDrive/final project/code/streamlit/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n","\u001b[34m  Stopping...\u001b[0m\n","^C\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wKkt7GqscGqz"},"execution_count":null,"outputs":[]}]}